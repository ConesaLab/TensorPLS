% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Tensor.R
\name{prepare_omics}
\alias{prepare_omics}
\title{Prepare omics data for downstream modelling}
\usage{
prepare_omics(
  config = NULL,
  data,
  id_col,
  time_col = NULL,
  transpose = "auto",
  header_in_row = TRUE,
  cohort = NULL,
  cohort_id_col = id_col,
  cohort_filter = NULL,
  min_timepoints = NULL,
  tensor = TRUE,
  exclude_cols = NULL,
  feature_cols = NULL,
  subjects = NULL,
  time_points = NULL,
  numeric_coercion = TRUE,
  legacy_na = FALSE,
  deduplicate = c("first", "last", "mean")
)
}
\arguments{
\item{config}{Either a YAML file path or a named list whose entries act
as default arguments. Optional.}

\item{data}{Data.frame, matrix/array, or a readable file path.}

\item{id_col}{Character; name of the subject identifier column.}

\item{time_col}{Character; name of the time-point column. If \code{NULL}
or not present in \code{data}, a 2-D matrix is produced.}

\item{transpose}{One of \code{"auto"}, \code{"never"}, \code{"always"}; passed to
\code{.transpose_if_needed()}.}

\item{header_in_row}{Logical; used only when transposing.}

\item{cohort}{Optional data.frame or file path containing metadata.}

\item{cohort_id_col}{Column in \code{cohort} matching \code{id_col}.}

\item{cohort_filter}{Character scalar; an R expression evaluated within
\code{cohort} to subset rows.}

\item{min_timepoints}{Integer; keep only subjects observed at least this
many times.}

\item{tensor}{Logical; if \code{FALSE}, return the (filtered) data.frame
rather than tensor/matrix.}

\item{exclude_cols}{Columns to drop entirely when building features.}

\item{feature_cols}{Character vector; explicit feature columns to keep.
Overrides \code{exclude_cols}.}

\item{subjects}{Optional character vector defining the order (and subset)
of subjects in the tensor/matrix.}

\item{time_points}{Optional vector defining the order (and subset) of
time points in the tensor.}

\item{numeric_coercion}{Logical; if \code{TRUE} attempt to coerce all columns
to numeric (ignored when \code{legacy_na = TRUE}).}

\item{legacy_na}{Logical; reproduces historical NA-handling rules and
forces \code{deduplicate = "first"}.}

\item{deduplicate}{Strategy used when duplicate subject/time pairs are
encountered: \code{"first"}, \code{"last"}, or \code{"mean"}.}
}
\value{
\itemize{
\item \strong{3-D numeric array} (Subj × Feat × Time) if
\code{tensor = TRUE} and a valid \code{time_col} is given;
\item \strong{2-D numeric matrix} (Subj × Feat) if
\code{tensor = TRUE} but no time column is available;
\item \strong{data.frame} after filtering/coercion if
\code{tensor = FALSE}.
}
}
\description{
Reads raw tabular data (long or wide), applies a series of
preprocessing steps (optional transposition, numeric coercion, cohort
filtering, duplicate handling, etc.) and returns either
\emph{-} a three-dimensional \strong{tensor}
(\emph{Subject × Feature × Time}) \emph{or}
\emph{-} a two-dimensional \strong{matrix}
(\emph{Subject × Feature}), depending on the presence of a time column or
the \code{tensor} flag.
}
\section{Workflow in brief}{

\enumerate{
\item \strong{YAML preset}\\
If \code{config} is supplied (file path or list) its values become
defaults; arguments given explicitly in the function call
always override the YAML.
\item \strong{Input loading}\\
\code{data} and, if applicable, \code{cohort} may be in-memory objects or
file paths (\code{csv}, \code{tsv}, \code{rds}, \code{feather}, \code{parquet}).
\item \strong{Transpose (optional)} via \code{.transpose_if_needed()}.
\item \strong{Numeric coercion} (legacy vs.\ modern rules).
\item \strong{Cohort filter} applied on an auxiliary table.
\item \strong{Minimum time-points} filter.
\item \strong{Tensor / matrix creation} through
\code{.build_tensor()}.
}
}

\examples{
## Minimal runnable example using package-internal demo files
raw_path    <- system.file("extdata", "GCTOF_Data_Processed.csv",
                           package = "myOmics")
cohort_path <- system.file("extdata", "CohortData.csv",
                           package = "myOmics")

arr <- prepare_omics(
  data          = raw_path,
  id_col        = "Individual.Id",
  time_col      = "Time.to.IA",
  transpose     = "always",
  legacy_na     = TRUE,
  cohort        = cohort_path,
  cohort_id_col = "Group.Id",
  cohort_filter = "Model.or.Validation=='Model'"
)
dim(arr)

}
\seealso{
\code{\link{load_and_prepare_omics_data}} for a high-level
TEDDY-specific wrapper.
}
