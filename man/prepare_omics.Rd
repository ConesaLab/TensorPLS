% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Tensor.R
\name{prepare_omics}
\alias{prepare_omics}
\title{Prepare omics data for downstream analysis (3D tensor)}
\usage{
prepare_omics(
  data,
  id_col,
  time_col,
  transpose = "auto",
  header_in_row = TRUE,
  cohort = NULL,
  cohort_id_col = id_col,
  cohort_filter = NULL,
  min_timepoints = NULL,
  exclude_cols = NULL,
  feature_cols = NULL,
  subjects = NULL,
  time_points = NULL,
  coercion_mode = c("force_numeric", "force_character", "custom"),
  id_as = c("numeric", "character"),
  time_as = c("numeric", "character", "date"),
  features_numeric = TRUE,
  deduplicate = c("first", "last", "mean")
)
}
\arguments{
\item{data}{Data.frame, matrix/array, or a readable file path.}

\item{id_col}{Character; subject identifier column name.}

\item{time_col}{Character; time-point column name (required).}

\item{transpose}{One of \code{"auto"}, \code{"never"}, \code{"always"}; passed to
\code{.transpose_if_needed()}.}

\item{header_in_row}{Logical; used only when transposing.}

\item{cohort}{Optional data.frame or file path with metadata.}

\item{cohort_id_col}{Column in \code{cohort} matching \code{id_col}.}

\item{cohort_filter}{Character scalar; an R expression evaluated within
\code{cohort} to subset rows.}

\item{min_timepoints}{Integer; keep only subjects observed at least this
many times.}

\item{exclude_cols}{Columns to drop entirely when building features.}

\item{feature_cols}{Character vector; explicit feature columns to keep.
Overrides \code{exclude_cols}.}

\item{subjects}{Optional character vector defining order (and subset) of
subjects in the tensor.}

\item{time_points}{Optional vector defining order (and subset) of time points
in the tensor.}

\item{coercion_mode}{One of \code{"force_numeric"}, \code{"force_character"}, \code{"custom"}.
\itemize{
\item \code{"force_numeric"}: ID/TIME coerced to numeric; features numeric; forces \code{deduplicate="first"}.
\item \code{"force_character"}: ID/TIME as character; features not forced.
\item \code{"custom"}: use \code{id_as}, \code{time_as}, \code{features_numeric}.
}}

\item{id_as}{(custom only) One of \code{"numeric"}, \code{"character"}.}

\item{time_as}{(custom only) One of \code{"numeric"}, \code{"character"}, \code{"date"}.}

\item{features_numeric}{Logical; if \code{TRUE} (default), coerce features to numeric.}

\item{deduplicate}{Strategy when duplicate subject/time pairs are found:
\code{"first"}, \code{"last"}, or \code{"mean"}.}
}
\value{
3-D numeric array (Subject × Feature × Time).
}
\description{
Reads tabular data (long or wide), applies preprocessing steps (optional
transpose, type/NA normalization, cohort filtering, duplicate handling),
and returns a 3-D numeric tensor \emph{(Subject × Feature × Time)}.
}
\details{
The function always builds a 3-D tensor; if \code{time_col} is missing or results
in zero valid time points after filtering/normalization, an explicit error is
raised.
}
\section{Workflow (brief)}{

\enumerate{
\item Input loading via \code{.read_or_pass()}.
\item Optional transpose via \code{.transpose_if_needed()}.
\item Type/NA normalization via \code{normalize_types_by_spec()} controlled by
\code{coercion_mode} (and, for \code{"custom"}, \code{id_as}/\code{time_as}/\code{features_numeric}).
\item Cohort filter (\code{cohort}, \code{cohort_filter}); ID type is aligned across tables.
\item Minimum time-points filter.
\item Guardrail: explicit error if the time axis would be empty.
\item Tensor creation via \code{.build_tensor()}.
}
}

\examples{
raw_path    <- system.file("extdata", "GCTOF_Data_Processed.csv",
                           package = "NPLS-Multiomi")
cohort_path <- system.file("extdata", "CohortData.csv",
                           package = "NPLS-Multiomi")
arr <- prepare_omics(
  data          = raw_path,
  id_col        = "Individual.Id",
  time_col      = "Time.to.IA",
  transpose     = "always",
  coercion_mode = "force_numeric",
  cohort        = cohort_path,
  cohort_id_col = "Group.Id",
  cohort_filter = "Model.or.Validation=='Model'"
)
dim(arr)

}
